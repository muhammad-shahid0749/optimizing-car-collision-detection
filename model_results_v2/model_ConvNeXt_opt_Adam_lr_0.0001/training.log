2025-05-03 11:45:26,214 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:26,214 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 709,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 11:45:26,214 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - No checkpoint found, starting fresh training
2025-05-03 11:45:26,215 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 1/20
2025-05-03 11:45:26,450 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - ERROR - Training interrupted: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 18.62 MiB is free. Including non-PyTorch memory, this process has 9.74 GiB memory in use. Process 1701407 has 5.91 GiB memory in use. Of the allocated memory 8.78 GiB is allocated by PyTorch, and 674.95 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-03 11:45:26,450 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Saving checkpoint before exit
2025-05-03 11:45:26,632 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 0
2025-05-03 11:45:27,288 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:27,288 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:27,288 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 710,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 11:45:27,288 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 710,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 11:45:27,288 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:27,288 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:27,560 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 1, best validation accuracy: 0.0000
2025-05-03 11:45:27,560 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 1, best validation accuracy: 0.0000
2025-05-03 11:45:27,562 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 2/20
2025-05-03 11:45:27,562 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 2/20
2025-05-03 11:45:27,846 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - ERROR - Training interrupted: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 18.62 MiB is free. Including non-PyTorch memory, this process has 9.74 GiB memory in use. Process 1701407 has 5.91 GiB memory in use. Of the allocated memory 8.76 GiB is allocated by PyTorch, and 691.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-03 11:45:27,846 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - ERROR - Training interrupted: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 18.62 MiB is free. Including non-PyTorch memory, this process has 9.74 GiB memory in use. Process 1701407 has 5.91 GiB memory in use. Of the allocated memory 8.76 GiB is allocated by PyTorch, and 691.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-03 11:45:27,847 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Saving checkpoint before exit
2025-05-03 11:45:27,847 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Saving checkpoint before exit
2025-05-03 11:45:28,170 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 1
2025-05-03 11:45:28,170 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 1
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 711,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 711,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 711,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:29,063 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:29,163 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 2, best validation accuracy: 0.0000
2025-05-03 11:45:29,163 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 2, best validation accuracy: 0.0000
2025-05-03 11:45:29,163 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 2, best validation accuracy: 0.0000
2025-05-03 11:45:29,164 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 3/20
2025-05-03 11:45:29,164 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 3/20
2025-05-03 11:45:29,164 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 3/20
2025-05-03 11:45:29,523 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - ERROR - Training interrupted: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 16.62 MiB is free. Including non-PyTorch memory, this process has 9.74 GiB memory in use. Process 1701407 has 5.91 GiB memory in use. Of the allocated memory 8.98 GiB is allocated by PyTorch, and 472.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-03 11:45:29,523 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - ERROR - Training interrupted: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 16.62 MiB is free. Including non-PyTorch memory, this process has 9.74 GiB memory in use. Process 1701407 has 5.91 GiB memory in use. Of the allocated memory 8.98 GiB is allocated by PyTorch, and 472.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-03 11:45:29,523 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - ERROR - Training interrupted: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 15.70 GiB of which 16.62 MiB is free. Including non-PyTorch memory, this process has 9.74 GiB memory in use. Process 1701407 has 5.91 GiB memory in use. Of the allocated memory 8.98 GiB is allocated by PyTorch, and 472.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-05-03 11:45:29,524 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Saving checkpoint before exit
2025-05-03 11:45:29,524 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Saving checkpoint before exit
2025-05-03 11:45:29,524 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Saving checkpoint before exit
2025-05-03 11:45:29,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 2
2025-05-03 11:45:29,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 2
2025-05-03 11:45:29,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 2
2025-05-03 11:45:30,558 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:30,558 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:30,558 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:30,558 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 712,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 712,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 712,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 712,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:30,559 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 11:45:30,659 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 3, best validation accuracy: 0.0000
2025-05-03 11:45:30,659 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 3, best validation accuracy: 0.0000
2025-05-03 11:45:30,659 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 3, best validation accuracy: 0.0000
2025-05-03 11:45:30,659 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 3, best validation accuracy: 0.0000
2025-05-03 11:45:30,660 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 4/20
2025-05-03 11:45:30,660 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 4/20
2025-05-03 11:45:30,660 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 4/20
2025-05-03 11:45:30,660 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 4/20
2025-05-03 11:46:17,083 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:46:17,083 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:46:17,083 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:46:17,083 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:47:12,681 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.0000 to 0.9503
2025-05-03 11:47:12,681 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.0000 to 0.9503
2025-05-03 11:47:12,681 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.0000 to 0.9503
2025-05-03 11:47:12,681 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.0000 to 0.9503
2025-05-03 11:47:12,870 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 4 completed in 102.21s - Train Loss: 0.4197, Train Acc: 0.8934, Val Loss: 0.3591, Val Acc: 0.9503
2025-05-03 11:47:12,870 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 4 completed in 102.21s - Train Loss: 0.4197, Train Acc: 0.8934, Val Loss: 0.3591, Val Acc: 0.9503
2025-05-03 11:47:12,870 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 4 completed in 102.21s - Train Loss: 0.4197, Train Acc: 0.8934, Val Loss: 0.3591, Val Acc: 0.9503
2025-05-03 11:47:12,870 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 4 completed in 102.21s - Train Loss: 0.4197, Train Acc: 0.8934, Val Loss: 0.3591, Val Acc: 0.9503
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 5/20
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 5/20
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 5/20
2025-05-03 11:47:13,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 5/20
2025-05-03 11:48:00,001 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:00,001 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:00,001 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:00,001 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:55,619 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9503 to 0.9605
2025-05-03 11:48:55,619 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9503 to 0.9605
2025-05-03 11:48:55,619 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9503 to 0.9605
2025-05-03 11:48:55,619 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9503 to 0.9605
2025-05-03 11:48:55,908 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 5 completed in 102.24s - Train Loss: 0.3578, Train Acc: 0.9571, Val Loss: 0.3521, Val Acc: 0.9605
2025-05-03 11:48:55,908 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 5 completed in 102.24s - Train Loss: 0.3578, Train Acc: 0.9571, Val Loss: 0.3521, Val Acc: 0.9605
2025-05-03 11:48:55,908 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 5 completed in 102.24s - Train Loss: 0.3578, Train Acc: 0.9571, Val Loss: 0.3521, Val Acc: 0.9605
2025-05-03 11:48:55,908 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 5 completed in 102.24s - Train Loss: 0.3578, Train Acc: 0.9571, Val Loss: 0.3521, Val Acc: 0.9605
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 6/20
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 6/20
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 6/20
2025-05-03 11:48:56,726 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 6/20
2025-05-03 11:49:43,019 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:49:43,019 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:49:43,019 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:49:43,019 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:50:36,459 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9605 to 0.9674
2025-05-03 11:50:36,459 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9605 to 0.9674
2025-05-03 11:50:36,459 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9605 to 0.9674
2025-05-03 11:50:36,459 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9605 to 0.9674
2025-05-03 11:50:36,737 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 6 completed in 100.01s - Train Loss: 0.3504, Train Acc: 0.9612, Val Loss: 0.3453, Val Acc: 0.9674
2025-05-03 11:50:36,737 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 6 completed in 100.01s - Train Loss: 0.3504, Train Acc: 0.9612, Val Loss: 0.3453, Val Acc: 0.9674
2025-05-03 11:50:36,737 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 6 completed in 100.01s - Train Loss: 0.3504, Train Acc: 0.9612, Val Loss: 0.3453, Val Acc: 0.9674
2025-05-03 11:50:36,737 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 6 completed in 100.01s - Train Loss: 0.3504, Train Acc: 0.9612, Val Loss: 0.3453, Val Acc: 0.9674
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 7/20
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 7/20
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 7/20
2025-05-03 11:50:37,563 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 7/20
2025-05-03 11:51:23,172 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:51:23,172 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:51:23,172 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:51:23,172 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:52:16,964 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from inf to 0.3490
2025-05-03 11:52:16,964 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from inf to 0.3490
2025-05-03 11:52:16,964 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from inf to 0.3490
2025-05-03 11:52:16,964 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from inf to 0.3490
2025-05-03 11:52:17,252 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 7 completed in 99.69s - Train Loss: 0.3496, Train Acc: 0.9625, Val Loss: 0.3490, Val Acc: 0.9631
2025-05-03 11:52:17,252 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 7 completed in 99.69s - Train Loss: 0.3496, Train Acc: 0.9625, Val Loss: 0.3490, Val Acc: 0.9631
2025-05-03 11:52:17,252 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 7 completed in 99.69s - Train Loss: 0.3496, Train Acc: 0.9625, Val Loss: 0.3490, Val Acc: 0.9631
2025-05-03 11:52:17,252 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 7 completed in 99.69s - Train Loss: 0.3496, Train Acc: 0.9625, Val Loss: 0.3490, Val Acc: 0.9631
2025-05-03 11:52:18,034 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:52:18,034 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:52:18,034 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:52:18,034 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 11:52:18,035 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 8/20
2025-05-03 11:52:18,035 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 8/20
2025-05-03 11:52:18,035 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 8/20
2025-05-03 11:52:18,035 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 8/20
2025-05-03 11:53:02,056 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:02,056 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:02,056 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:02,056 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:54,233 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 8 completed in 96.20s - Train Loss: 0.3433, Train Acc: 0.9683, Val Loss: 0.3645, Val Acc: 0.9477
2025-05-03 11:53:54,233 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 8 completed in 96.20s - Train Loss: 0.3433, Train Acc: 0.9683, Val Loss: 0.3645, Val Acc: 0.9477
2025-05-03 11:53:54,233 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 8 completed in 96.20s - Train Loss: 0.3433, Train Acc: 0.9683, Val Loss: 0.3645, Val Acc: 0.9477
2025-05-03 11:53:54,233 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 8 completed in 96.20s - Train Loss: 0.3433, Train Acc: 0.9683, Val Loss: 0.3645, Val Acc: 0.9477
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 9/20
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 9/20
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 9/20
2025-05-03 11:53:55,064 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 9/20
2025-05-03 11:54:41,493 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:54:41,493 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:54:41,493 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:54:41,493 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:55:35,486 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 9 completed in 100.42s - Train Loss: 0.3385, Train Acc: 0.9740, Val Loss: 0.3534, Val Acc: 0.9571
2025-05-03 11:55:35,486 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 9 completed in 100.42s - Train Loss: 0.3385, Train Acc: 0.9740, Val Loss: 0.3534, Val Acc: 0.9571
2025-05-03 11:55:35,486 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 9 completed in 100.42s - Train Loss: 0.3385, Train Acc: 0.9740, Val Loss: 0.3534, Val Acc: 0.9571
2025-05-03 11:55:35,486 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 9 completed in 100.42s - Train Loss: 0.3385, Train Acc: 0.9740, Val Loss: 0.3534, Val Acc: 0.9571
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 10/20
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 10/20
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 10/20
2025-05-03 11:55:36,322 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 10/20
2025-05-03 11:56:21,654 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:56:21,654 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:56:21,654 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:56:21,654 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:57:15,889 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 10 completed in 99.57s - Train Loss: 0.3446, Train Acc: 0.9685, Val Loss: 0.3583, Val Acc: 0.9545
2025-05-03 11:57:15,889 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 10 completed in 99.57s - Train Loss: 0.3446, Train Acc: 0.9685, Val Loss: 0.3583, Val Acc: 0.9545
2025-05-03 11:57:15,889 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 10 completed in 99.57s - Train Loss: 0.3446, Train Acc: 0.9685, Val Loss: 0.3583, Val Acc: 0.9545
2025-05-03 11:57:15,889 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 10 completed in 99.57s - Train Loss: 0.3446, Train Acc: 0.9685, Val Loss: 0.3583, Val Acc: 0.9545
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 11/20
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 11/20
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 11/20
2025-05-03 11:57:16,723 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 11/20
2025-05-03 11:58:02,535 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:02,535 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:02,535 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:02,535 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:55,977 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 11 completed in 99.25s - Train Loss: 0.3414, Train Acc: 0.9710, Val Loss: 0.3543, Val Acc: 0.9571
2025-05-03 11:58:55,977 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 11 completed in 99.25s - Train Loss: 0.3414, Train Acc: 0.9710, Val Loss: 0.3543, Val Acc: 0.9571
2025-05-03 11:58:55,977 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 11 completed in 99.25s - Train Loss: 0.3414, Train Acc: 0.9710, Val Loss: 0.3543, Val Acc: 0.9571
2025-05-03 11:58:55,977 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 11 completed in 99.25s - Train Loss: 0.3414, Train Acc: 0.9710, Val Loss: 0.3543, Val Acc: 0.9571
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 12/20
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 12/20
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 12/20
2025-05-03 11:58:56,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 12/20
2025-05-03 11:59:42,361 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 11:59:42,361 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 11:59:42,361 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 11:59:42,361 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 12:00:35,882 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 12 completed in 99.12s - Train Loss: 0.3408, Train Acc: 0.9715, Val Loss: 0.3579, Val Acc: 0.9545
2025-05-03 12:00:35,882 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 12 completed in 99.12s - Train Loss: 0.3408, Train Acc: 0.9715, Val Loss: 0.3579, Val Acc: 0.9545
2025-05-03 12:00:35,882 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 12 completed in 99.12s - Train Loss: 0.3408, Train Acc: 0.9715, Val Loss: 0.3579, Val Acc: 0.9545
2025-05-03 12:00:35,882 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 12 completed in 99.12s - Train Loss: 0.3408, Train Acc: 0.9715, Val Loss: 0.3579, Val Acc: 0.9545
2025-05-03 12:00:36,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 12:00:36,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 12:00:36,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 12:00:36,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Early stopping triggered after 12 epochs
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Early stopping triggered after 12 epochs
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Early stopping triggered after 12 epochs
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Early stopping triggered after 12 epochs
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 906.10 seconds
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 906.10 seconds
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 906.10 seconds
2025-05-03 12:00:36,671 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 906.10 seconds
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 713,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 713,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 713,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 713,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 713,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:00:49,208 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:00:49,735 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 12, best validation accuracy: 0.9674
2025-05-03 12:00:49,735 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 12, best validation accuracy: 0.9674
2025-05-03 12:00:49,735 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 12, best validation accuracy: 0.9674
2025-05-03 12:00:49,735 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 12, best validation accuracy: 0.9674
2025-05-03 12:00:49,735 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 12, best validation accuracy: 0.9674
2025-05-03 12:00:49,736 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 13/20
2025-05-03 12:00:49,736 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 13/20
2025-05-03 12:00:49,736 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 13/20
2025-05-03 12:00:49,736 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 13/20
2025-05-03 12:00:49,736 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 13/20
2025-05-03 12:01:35,625 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:01:35,625 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:01:35,625 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:01:35,625 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:01:35,625 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:02:31,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9674 to 0.9708
2025-05-03 12:02:31,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9674 to 0.9708
2025-05-03 12:02:31,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9674 to 0.9708
2025-05-03 12:02:31,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9674 to 0.9708
2025-05-03 12:02:31,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9674 to 0.9708
2025-05-03 12:02:31,353 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 13 completed in 101.62s - Train Loss: 0.0093, Train Acc: 0.9768, Val Loss: 0.0102, Val Acc: 0.9708
2025-05-03 12:02:31,353 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 13 completed in 101.62s - Train Loss: 0.0093, Train Acc: 0.9768, Val Loss: 0.0102, Val Acc: 0.9708
2025-05-03 12:02:31,353 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 13 completed in 101.62s - Train Loss: 0.0093, Train Acc: 0.9768, Val Loss: 0.0102, Val Acc: 0.9708
2025-05-03 12:02:31,353 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 13 completed in 101.62s - Train Loss: 0.0093, Train Acc: 0.9768, Val Loss: 0.0102, Val Acc: 0.9708
2025-05-03 12:02:31,353 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 13 completed in 101.62s - Train Loss: 0.0093, Train Acc: 0.9768, Val Loss: 0.0102, Val Acc: 0.9708
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 14/20
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 14/20
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 14/20
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 14/20
2025-05-03 12:02:32,140 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 14/20
2025-05-03 12:03:17,773 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:03:17,773 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:03:17,773 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:03:17,773 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:03:17,773 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:04:11,160 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9708 to 0.9811
2025-05-03 12:04:11,160 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9708 to 0.9811
2025-05-03 12:04:11,160 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9708 to 0.9811
2025-05-03 12:04:11,160 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9708 to 0.9811
2025-05-03 12:04:11,160 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9708 to 0.9811
2025-05-03 12:04:11,451 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 14 completed in 99.31s - Train Loss: 0.0086, Train Acc: 0.9809, Val Loss: 0.0088, Val Acc: 0.9811
2025-05-03 12:04:11,451 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 14 completed in 99.31s - Train Loss: 0.0086, Train Acc: 0.9809, Val Loss: 0.0088, Val Acc: 0.9811
2025-05-03 12:04:11,451 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 14 completed in 99.31s - Train Loss: 0.0086, Train Acc: 0.9809, Val Loss: 0.0088, Val Acc: 0.9811
2025-05-03 12:04:11,451 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 14 completed in 99.31s - Train Loss: 0.0086, Train Acc: 0.9809, Val Loss: 0.0088, Val Acc: 0.9811
2025-05-03 12:04:11,451 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 14 completed in 99.31s - Train Loss: 0.0086, Train Acc: 0.9809, Val Loss: 0.0088, Val Acc: 0.9811
2025-05-03 12:04:12,237 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:04:12,237 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:04:12,237 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:04:12,237 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:04:12,237 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 12:04:12,238 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 15/20
2025-05-03 12:04:12,238 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 15/20
2025-05-03 12:04:12,238 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 15/20
2025-05-03 12:04:12,238 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 15/20
2025-05-03 12:04:12,238 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 15/20
2025-05-03 12:04:57,699 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:04:57,699 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:04:57,699 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:04:57,699 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:04:57,699 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:05:50,689 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.3490 to 0.0087
2025-05-03 12:05:50,689 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.3490 to 0.0087
2025-05-03 12:05:50,689 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.3490 to 0.0087
2025-05-03 12:05:50,689 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.3490 to 0.0087
2025-05-03 12:05:50,689 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.3490 to 0.0087
2025-05-03 12:05:50,971 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 15 completed in 98.73s - Train Loss: 0.0076, Train Acc: 0.9856, Val Loss: 0.0087, Val Acc: 0.9803
2025-05-03 12:05:50,971 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 15 completed in 98.73s - Train Loss: 0.0076, Train Acc: 0.9856, Val Loss: 0.0087, Val Acc: 0.9803
2025-05-03 12:05:50,971 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 15 completed in 98.73s - Train Loss: 0.0076, Train Acc: 0.9856, Val Loss: 0.0087, Val Acc: 0.9803
2025-05-03 12:05:50,971 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 15 completed in 98.73s - Train Loss: 0.0076, Train Acc: 0.9856, Val Loss: 0.0087, Val Acc: 0.9803
2025-05-03 12:05:50,971 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 15 completed in 98.73s - Train Loss: 0.0076, Train Acc: 0.9856, Val Loss: 0.0087, Val Acc: 0.9803
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 16/20
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 16/20
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 16/20
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 16/20
2025-05-03 12:05:51,764 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 16/20
2025-05-03 12:06:37,871 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:06:37,871 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:06:37,871 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:06:37,871 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:06:37,871 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:07:31,942 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9811 to 0.9828
2025-05-03 12:07:31,942 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9811 to 0.9828
2025-05-03 12:07:31,942 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9811 to 0.9828
2025-05-03 12:07:31,942 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9811 to 0.9828
2025-05-03 12:07:31,942 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9811 to 0.9828
2025-05-03 12:07:32,226 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 16 completed in 100.46s - Train Loss: 0.0073, Train Acc: 0.9893, Val Loss: 0.0083, Val Acc: 0.9828
2025-05-03 12:07:32,226 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 16 completed in 100.46s - Train Loss: 0.0073, Train Acc: 0.9893, Val Loss: 0.0083, Val Acc: 0.9828
2025-05-03 12:07:32,226 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 16 completed in 100.46s - Train Loss: 0.0073, Train Acc: 0.9893, Val Loss: 0.0083, Val Acc: 0.9828
2025-05-03 12:07:32,226 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 16 completed in 100.46s - Train Loss: 0.0073, Train Acc: 0.9893, Val Loss: 0.0083, Val Acc: 0.9828
2025-05-03 12:07:32,226 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 16 completed in 100.46s - Train Loss: 0.0073, Train Acc: 0.9893, Val Loss: 0.0083, Val Acc: 0.9828
2025-05-03 12:07:33,061 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:07:33,061 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:07:33,061 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:07:33,061 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:07:33,061 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 12:07:33,062 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 17/20
2025-05-03 12:07:33,062 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 17/20
2025-05-03 12:07:33,062 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 17/20
2025-05-03 12:07:33,062 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 17/20
2025-05-03 12:07:33,062 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 17/20
2025-05-03 12:08:18,268 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:08:18,268 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:08:18,268 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:08:18,268 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:08:18,268 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:09:13,490 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9828 to 0.9854
2025-05-03 12:09:13,490 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9828 to 0.9854
2025-05-03 12:09:13,490 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9828 to 0.9854
2025-05-03 12:09:13,490 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9828 to 0.9854
2025-05-03 12:09:13,490 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation accuracy improved from 0.9828 to 0.9854
2025-05-03 12:09:13,783 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 17 completed in 100.72s - Train Loss: 0.0074, Train Acc: 0.9886, Val Loss: 0.0077, Val Acc: 0.9854
2025-05-03 12:09:13,783 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 17 completed in 100.72s - Train Loss: 0.0074, Train Acc: 0.9886, Val Loss: 0.0077, Val Acc: 0.9854
2025-05-03 12:09:13,783 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 17 completed in 100.72s - Train Loss: 0.0074, Train Acc: 0.9886, Val Loss: 0.0077, Val Acc: 0.9854
2025-05-03 12:09:13,783 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 17 completed in 100.72s - Train Loss: 0.0074, Train Acc: 0.9886, Val Loss: 0.0077, Val Acc: 0.9854
2025-05-03 12:09:13,783 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 17 completed in 100.72s - Train Loss: 0.0074, Train Acc: 0.9886, Val Loss: 0.0077, Val Acc: 0.9854
2025-05-03 12:09:14,610 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:09:14,610 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:09:14,610 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:09:14,610 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:09:14,610 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 12:09:14,611 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 18/20
2025-05-03 12:09:14,611 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 18/20
2025-05-03 12:09:14,611 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 18/20
2025-05-03 12:09:14,611 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 18/20
2025-05-03 12:09:14,611 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 18/20
2025-05-03 12:09:59,919 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:09:59,919 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:09:59,919 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:09:59,919 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:09:59,919 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:10:54,679 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0087 to 0.0085
2025-05-03 12:10:54,679 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0087 to 0.0085
2025-05-03 12:10:54,679 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0087 to 0.0085
2025-05-03 12:10:54,679 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0087 to 0.0085
2025-05-03 12:10:54,679 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0087 to 0.0085
2025-05-03 12:10:54,959 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 18 completed in 100.35s - Train Loss: 0.0070, Train Acc: 0.9912, Val Loss: 0.0085, Val Acc: 0.9820
2025-05-03 12:10:54,959 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 18 completed in 100.35s - Train Loss: 0.0070, Train Acc: 0.9912, Val Loss: 0.0085, Val Acc: 0.9820
2025-05-03 12:10:54,959 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 18 completed in 100.35s - Train Loss: 0.0070, Train Acc: 0.9912, Val Loss: 0.0085, Val Acc: 0.9820
2025-05-03 12:10:54,959 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 18 completed in 100.35s - Train Loss: 0.0070, Train Acc: 0.9912, Val Loss: 0.0085, Val Acc: 0.9820
2025-05-03 12:10:54,959 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 18 completed in 100.35s - Train Loss: 0.0070, Train Acc: 0.9912, Val Loss: 0.0085, Val Acc: 0.9820
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 19/20
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 19/20
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 19/20
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 19/20
2025-05-03 12:10:55,775 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 19/20
2025-05-03 12:11:40,444 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:11:40,444 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:11:40,444 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:11:40,444 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:11:40,444 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:12:34,702 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0085 to 0.0082
2025-05-03 12:12:34,702 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0085 to 0.0082
2025-05-03 12:12:34,702 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0085 to 0.0082
2025-05-03 12:12:34,702 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0085 to 0.0082
2025-05-03 12:12:34,702 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0085 to 0.0082
2025-05-03 12:12:34,987 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 19 completed in 99.21s - Train Loss: 0.0068, Train Acc: 0.9927, Val Loss: 0.0082, Val Acc: 0.9828
2025-05-03 12:12:34,987 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 19 completed in 99.21s - Train Loss: 0.0068, Train Acc: 0.9927, Val Loss: 0.0082, Val Acc: 0.9828
2025-05-03 12:12:34,987 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 19 completed in 99.21s - Train Loss: 0.0068, Train Acc: 0.9927, Val Loss: 0.0082, Val Acc: 0.9828
2025-05-03 12:12:34,987 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 19 completed in 99.21s - Train Loss: 0.0068, Train Acc: 0.9927, Val Loss: 0.0082, Val Acc: 0.9828
2025-05-03 12:12:34,987 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 19 completed in 99.21s - Train Loss: 0.0068, Train Acc: 0.9927, Val Loss: 0.0082, Val Acc: 0.9828
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 20/20
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 20/20
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 20/20
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 20/20
2025-05-03 12:12:35,758 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Starting epoch 20/20
2025-05-03 12:13:21,099 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:13:21,099 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:13:21,099 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:13:21,099 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:13:21,099 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:14:15,877 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0082 to 0.0079
2025-05-03 12:14:15,877 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0082 to 0.0079
2025-05-03 12:14:15,877 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0082 to 0.0079
2025-05-03 12:14:15,877 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0082 to 0.0079
2025-05-03 12:14:15,877 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Validation loss improved from 0.0082 to 0.0079
2025-05-03 12:14:16,141 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 20 completed in 100.38s - Train Loss: 0.0065, Train Acc: 0.9944, Val Loss: 0.0079, Val Acc: 0.9854
2025-05-03 12:14:16,141 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 20 completed in 100.38s - Train Loss: 0.0065, Train Acc: 0.9944, Val Loss: 0.0079, Val Acc: 0.9854
2025-05-03 12:14:16,141 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 20 completed in 100.38s - Train Loss: 0.0065, Train Acc: 0.9944, Val Loss: 0.0079, Val Acc: 0.9854
2025-05-03 12:14:16,141 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 20 completed in 100.38s - Train Loss: 0.0065, Train Acc: 0.9944, Val Loss: 0.0079, Val Acc: 0.9854
2025-05-03 12:14:16,141 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Epoch 20 completed in 100.38s - Train Loss: 0.0065, Train Acc: 0.9944, Val Loss: 0.0079, Val Acc: 0.9854
2025-05-03 12:14:16,933 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:14:16,933 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:14:16,933 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:14:16,933 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:14:16,933 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 12:14:16,934 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:16,934 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:16,934 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:16,934 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:16,934 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 714,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 714,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 714,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 714,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 714,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 714,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:29,102 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:29,627 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:29,627 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:29,627 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:29,627 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:29,627 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:29,627 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:29,628 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:29,628 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:29,628 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:29,628 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:29,628 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:29,628 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 715,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:41,713 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,191 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:42,193 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 716,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:54,526 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,054 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:14:55,055 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 717,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,298 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,815 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:07,816 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 718,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,293 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,796 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:20,798 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 719,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,264 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,749 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:33,751 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_Adam_lr_0.0001
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,186 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Config: {
  "id": 720,
  "model_name": "ConvNeXt",
  "optimizer": "Adam",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,187 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_Adam_lr_0.0001/checkpoint.pt
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,669 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
2025-05-03 12:15:46,670 - training.model_ConvNeXt_opt_Adam_lr_0.0001 - INFO - Training completed after 1712.51 seconds
