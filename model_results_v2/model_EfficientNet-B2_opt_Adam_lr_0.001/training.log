2025-05-01 08:40:22,986 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:40:22,986 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 265,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 08:40:22,986 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - No checkpoint found, starting fresh training
2025-05-01 08:40:22,987 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 1/20
2025-05-01 08:40:47,026 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 0
2025-05-01 08:41:18,935 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.0000 to 0.8636
2025-05-01 08:41:18,964 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 1 completed in 55.98s - Train Loss: 0.4785, Train Acc: 0.8260, Val Loss: 0.4448, Val Acc: 0.8636
2025-05-01 08:41:19,068 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 0
2025-05-01 08:41:19,069 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 2/20
2025-05-01 08:41:43,359 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 1
2025-05-01 08:42:16,022 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from inf to 0.4972
2025-05-01 08:42:16,061 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 2 completed in 56.99s - Train Loss: 0.4517, Train Acc: 0.8578, Val Loss: 0.4972, Val Acc: 0.8130
2025-05-01 08:42:16,164 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 1
2025-05-01 08:42:16,165 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 3/20
2025-05-01 08:42:40,744 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 2
2025-05-01 08:43:12,132 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.8636 to 0.8971
2025-05-01 08:43:12,170 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 3 completed in 56.01s - Train Loss: 0.4329, Train Acc: 0.8792, Val Loss: 0.4131, Val Acc: 0.8971
2025-05-01 08:43:12,271 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 2
2025-05-01 08:43:12,271 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 4/20
2025-05-01 08:43:36,341 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 3
2025-05-01 08:44:09,002 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.8971 to 0.9288
2025-05-01 08:44:09,040 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 4 completed in 56.77s - Train Loss: 0.4079, Train Acc: 0.9026, Val Loss: 0.3809, Val Acc: 0.9288
2025-05-01 08:44:09,139 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 3
2025-05-01 08:44:09,139 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 5/20
2025-05-01 08:44:33,388 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 4
2025-05-01 08:45:05,980 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from 0.4972 to 0.3859
2025-05-01 08:45:06,029 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 5 completed in 56.89s - Train Loss: 0.3981, Train Acc: 0.9129, Val Loss: 0.3859, Val Acc: 0.9262
2025-05-01 08:45:06,124 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 4
2025-05-01 08:45:06,125 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 6/20
2025-05-01 08:45:29,927 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 5
2025-05-01 08:46:01,718 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9288 to 0.9305
2025-05-01 08:46:01,772 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 6 completed in 55.65s - Train Loss: 0.3863, Train Acc: 0.9260, Val Loss: 0.3809, Val Acc: 0.9305
2025-05-01 08:46:01,868 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 5
2025-05-01 08:46:01,868 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 7/20
2025-05-01 08:46:25,244 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 6
2025-05-01 08:46:58,024 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 7 completed in 56.16s - Train Loss: 0.3968, Train Acc: 0.9131, Val Loss: 0.4257, Val Acc: 0.8825
2025-05-01 08:46:58,139 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 6
2025-05-01 08:46:58,139 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 8/20
2025-05-01 08:47:22,244 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 7
2025-05-01 08:47:54,456 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9305 to 0.9374
2025-05-01 08:47:54,505 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 8 completed in 56.37s - Train Loss: 0.3866, Train Acc: 0.9243, Val Loss: 0.3748, Val Acc: 0.9374
2025-05-01 08:47:54,604 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 7
2025-05-01 08:47:54,605 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 9/20
2025-05-01 08:48:18,778 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 8
2025-05-01 08:48:52,118 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9374 to 0.9460
2025-05-01 08:48:52,169 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 9 completed in 57.56s - Train Loss: 0.3762, Train Acc: 0.9346, Val Loss: 0.3630, Val Acc: 0.9460
2025-05-01 08:48:52,266 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 8
2025-05-01 08:48:52,266 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 10/20
2025-05-01 08:49:16,742 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 9
2025-05-01 08:49:48,862 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from 0.3859 to 0.3703
2025-05-01 08:49:48,912 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 10 completed in 56.65s - Train Loss: 0.3673, Train Acc: 0.9444, Val Loss: 0.3703, Val Acc: 0.9425
2025-05-01 08:49:49,010 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 9
2025-05-01 08:49:49,010 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 11/20
2025-05-01 08:50:13,043 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 10
2025-05-01 08:50:45,317 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9460 to 0.9580
2025-05-01 08:50:45,359 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 11 completed in 56.35s - Train Loss: 0.3515, Train Acc: 0.9614, Val Loss: 0.3542, Val Acc: 0.9580
2025-05-01 08:50:45,461 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 10
2025-05-01 08:50:45,461 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 12/20
2025-05-01 08:51:10,237 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 11
2025-05-01 08:51:42,514 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9580 to 0.9605
2025-05-01 08:51:42,552 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 12 completed in 57.09s - Train Loss: 0.3412, Train Acc: 0.9706, Val Loss: 0.3525, Val Acc: 0.9605
2025-05-01 08:51:42,645 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 11
2025-05-01 08:51:42,645 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 13/20
2025-05-01 08:52:07,098 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 12
2025-05-01 08:52:38,441 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9605 to 0.9700
2025-05-01 08:52:38,480 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 13 completed in 55.83s - Train Loss: 0.3369, Train Acc: 0.9762, Val Loss: 0.3425, Val Acc: 0.9700
2025-05-01 08:52:38,579 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 12
2025-05-01 08:52:38,580 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 14/20
2025-05-01 08:53:02,145 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 13
2025-05-01 08:53:34,702 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from 0.3703 to 0.3455
2025-05-01 08:53:34,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 14 completed in 56.17s - Train Loss: 0.3339, Train Acc: 0.9790, Val Loss: 0.3455, Val Acc: 0.9666
2025-05-01 08:53:34,851 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 13
2025-05-01 08:53:34,851 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 15/20
2025-05-01 08:53:59,315 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 14
2025-05-01 08:54:32,075 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from 0.3455 to 0.3433
2025-05-01 08:54:32,113 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 15 completed in 57.26s - Train Loss: 0.3344, Train Acc: 0.9792, Val Loss: 0.3433, Val Acc: 0.9683
2025-05-01 08:54:32,211 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 14
2025-05-01 08:54:32,212 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 16/20
2025-05-01 08:54:56,908 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 15
2025-05-01 08:55:28,659 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 16 completed in 56.45s - Train Loss: 0.3327, Train Acc: 0.9807, Val Loss: 0.3459, Val Acc: 0.9657
2025-05-01 08:55:28,758 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 15
2025-05-01 08:55:28,758 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 17/20
2025-05-01 08:55:52,802 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 16
2025-05-01 08:56:25,440 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from 0.3433 to 0.3428
2025-05-01 08:56:25,481 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 17 completed in 56.72s - Train Loss: 0.3301, Train Acc: 0.9826, Val Loss: 0.3428, Val Acc: 0.9691
2025-05-01 08:56:25,582 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 16
2025-05-01 08:56:25,583 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 18/20
2025-05-01 08:56:49,344 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 17
2025-05-01 08:57:21,792 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9700 to 0.9726
2025-05-01 08:57:21,840 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 18 completed in 56.26s - Train Loss: 0.3294, Train Acc: 0.9843, Val Loss: 0.3402, Val Acc: 0.9726
2025-05-01 08:57:21,936 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 17
2025-05-01 08:57:21,937 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 19/20
2025-05-01 08:57:46,315 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 18
2025-05-01 08:58:18,581 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation loss improved from 0.3428 to 0.3399
2025-05-01 08:58:18,630 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 19 completed in 56.69s - Train Loss: 0.3297, Train Acc: 0.9833, Val Loss: 0.3399, Val Acc: 0.9726
2025-05-01 08:58:18,731 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 18
2025-05-01 08:58:18,732 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Starting epoch 20/20
2025-05-01 08:58:42,917 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 19
2025-05-01 08:59:15,601 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Validation accuracy improved from 0.9726 to 0.9760
2025-05-01 08:59:15,649 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Epoch 20 completed in 56.92s - Train Loss: 0.3271, Train Acc: 0.9865, Val Loss: 0.3379, Val Acc: 0.9760
2025-05-01 08:59:15,746 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Checkpoint saved at epoch 19
2025-05-01 08:59:15,747 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:27,264 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:27,264 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:27,264 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 266,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 08:59:27,264 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 266,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 08:59:27,264 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:27,264 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:28,127 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:28,127 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:28,129 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:28,129 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 267,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 267,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 267,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:39,529 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:40,456 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:40,456 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:40,456 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:40,458 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:40,458 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:40,458 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 268,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 268,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 268,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 268,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:51,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 08:59:52,568 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:52,568 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:52,568 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:52,568 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 08:59:52,569 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:52,569 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:52,569 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 08:59:52,569 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 269,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 269,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 269,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 269,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 269,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:03,673 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:04,610 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:04,610 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:04,610 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:04,610 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:04,610 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:04,611 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:04,611 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:04,611 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:04,611 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:04,611 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 270,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 270,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 270,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 270,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 270,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 270,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:15,863 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:16,719 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:16,719 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:16,719 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:16,719 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:16,719 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:16,719 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:16,720 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:16,720 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:16,720 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:16,720 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:16,720 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:16,720 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 271,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:27,928 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,727 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:28,728 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 272,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:39,952 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,751 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:40,753 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 273,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:51,856 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,620 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:00:52,621 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 274,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:03,961 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,888 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:04,889 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 275,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,171 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,968 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:16,970 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Initialized training manager for model_EfficientNet-B2_opt_Adam_lr_0.001
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,547 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Config: {
  "id": 276,
  "model_name": "EfficientNet-B2",
  "optimizer": "Adam",
  "learning_rate": 0.001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:28,548 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Loading checkpoint from model_results_v2/model_EfficientNet-B2_opt_Adam_lr_0.001/checkpoint.pt
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,389 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9760
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
2025-05-01 09:01:29,390 - training.model_EfficientNet-B2_opt_Adam_lr_0.001 - INFO - Training completed after 1132.66 seconds
