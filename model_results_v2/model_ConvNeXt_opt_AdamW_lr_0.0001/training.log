2025-05-03 13:23:07,883 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:23:07,883 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 745,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:23:07,883 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - No checkpoint found, starting fresh training
2025-05-03 13:23:07,884 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 1/20
2025-05-03 13:23:53,609 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 0
2025-05-03 13:24:48,498 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.0000 to 0.9563
2025-05-03 13:24:48,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 1 completed in 100.80s - Train Loss: 0.4212, Train Acc: 0.8876, Val Loss: 0.3590, Val Acc: 0.9563
2025-05-03 13:24:49,484 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 0
2025-05-03 13:24:49,484 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 2/20
2025-05-03 13:25:34,990 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 1
2025-05-03 13:26:29,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9563 to 0.9580
2025-05-03 13:26:29,613 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 2 completed in 100.13s - Train Loss: 0.3563, Train Acc: 0.9562, Val Loss: 0.3534, Val Acc: 0.9580
2025-05-03 13:26:30,424 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 1
2025-05-03 13:26:30,424 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 3/20
2025-05-03 13:27:16,579 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 2
2025-05-03 13:28:09,107 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9580 to 0.9640
2025-05-03 13:28:09,401 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 3 completed in 98.98s - Train Loss: 0.3523, Train Acc: 0.9603, Val Loss: 0.3463, Val Acc: 0.9640
2025-05-03 13:28:10,214 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 2
2025-05-03 13:28:10,214 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 4/20
2025-05-03 13:28:56,498 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 13:29:49,345 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9640 to 0.9683
2025-05-03 13:29:49,633 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 4 completed in 99.42s - Train Loss: 0.3418, Train Acc: 0.9715, Val Loss: 0.3434, Val Acc: 0.9683
2025-05-03 13:29:50,449 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 3
2025-05-03 13:29:50,449 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 5/20
2025-05-03 13:30:35,864 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 13:31:29,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from inf to 0.3460
2025-05-03 13:31:29,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 5 completed in 99.04s - Train Loss: 0.3399, Train Acc: 0.9734, Val Loss: 0.3460, Val Acc: 0.9666
2025-05-03 13:31:30,313 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 4
2025-05-03 13:31:30,313 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 6/20
2025-05-03 13:32:15,831 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 13:33:09,160 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9683 to 0.9700
2025-05-03 13:33:09,430 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 6 completed in 99.12s - Train Loss: 0.3386, Train Acc: 0.9734, Val Loss: 0.3420, Val Acc: 0.9700
2025-05-03 13:33:10,209 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 5
2025-05-03 13:33:10,210 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 7/20
2025-05-03 13:33:56,378 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 13:34:50,564 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3460 to 0.3455
2025-05-03 13:34:50,833 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 7 completed in 100.62s - Train Loss: 0.3356, Train Acc: 0.9766, Val Loss: 0.3455, Val Acc: 0.9657
2025-05-03 13:34:51,608 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 6
2025-05-03 13:34:51,608 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 8/20
2025-05-03 13:35:36,856 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 13:36:29,571 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9700 to 0.9708
2025-05-03 13:36:29,839 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 8 completed in 98.23s - Train Loss: 0.3336, Train Acc: 0.9792, Val Loss: 0.3419, Val Acc: 0.9708
2025-05-03 13:36:30,614 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 7
2025-05-03 13:36:30,614 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 9/20
2025-05-03 13:37:16,339 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 13:38:09,521 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9708 to 0.9837
2025-05-03 13:38:09,793 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 9 completed in 99.18s - Train Loss: 0.3341, Train Acc: 0.9788, Val Loss: 0.3297, Val Acc: 0.9837
2025-05-03 13:38:10,552 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 8
2025-05-03 13:38:10,552 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 10/20
2025-05-03 13:38:56,738 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 13:39:51,719 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3455 to 0.3446
2025-05-03 13:39:52,004 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 10 completed in 101.45s - Train Loss: 0.3285, Train Acc: 0.9841, Val Loss: 0.3446, Val Acc: 0.9683
2025-05-03 13:39:52,821 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 9
2025-05-03 13:39:52,822 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 11/20
2025-05-03 13:40:39,182 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 13:41:33,962 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3446 to 0.3343
2025-05-03 13:41:34,228 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 11 completed in 101.41s - Train Loss: 0.3279, Train Acc: 0.9852, Val Loss: 0.3343, Val Acc: 0.9794
2025-05-03 13:41:35,023 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 10
2025-05-03 13:41:35,023 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 12/20
2025-05-03 13:42:20,342 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 13:43:13,733 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3343 to 0.3341
2025-05-03 13:43:14,008 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 12 completed in 98.98s - Train Loss: 0.3225, Train Acc: 0.9906, Val Loss: 0.3341, Val Acc: 0.9794
2025-05-03 13:43:14,775 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 11
2025-05-03 13:43:14,776 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 13/20
2025-05-03 13:43:59,445 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 13:44:53,114 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3341 to 0.3323
2025-05-03 13:44:53,370 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 13 completed in 98.59s - Train Loss: 0.3204, Train Acc: 0.9931, Val Loss: 0.3323, Val Acc: 0.9803
2025-05-03 13:44:54,143 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 12
2025-05-03 13:44:54,144 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 14/20
2025-05-03 13:45:38,627 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 13:46:32,690 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 14 completed in 98.55s - Train Loss: 0.3209, Train Acc: 0.9923, Val Loss: 0.3331, Val Acc: 0.9803
2025-05-03 13:46:33,479 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 13
2025-05-03 13:46:33,480 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 15/20
2025-05-03 13:47:18,720 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 13:48:11,013 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3323 to 0.3313
2025-05-03 13:48:11,282 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 15 completed in 97.80s - Train Loss: 0.3222, Train Acc: 0.9910, Val Loss: 0.3313, Val Acc: 0.9803
2025-05-03 13:48:12,080 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 14
2025-05-03 13:48:12,080 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 16/20
2025-05-03 13:48:57,839 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 13:49:51,830 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3313 to 0.3309
2025-05-03 13:49:52,102 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 16 completed in 100.02s - Train Loss: 0.3208, Train Acc: 0.9921, Val Loss: 0.3309, Val Acc: 0.9820
2025-05-03 13:49:52,871 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 15
2025-05-03 13:49:52,871 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 17/20
2025-05-03 13:50:38,658 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 13:51:31,915 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation accuracy improved from 0.9837 to 0.9854
2025-05-03 13:51:32,194 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 17 completed in 99.32s - Train Loss: 0.3188, Train Acc: 0.9946, Val Loss: 0.3283, Val Acc: 0.9854
2025-05-03 13:51:32,995 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 16
2025-05-03 13:51:32,996 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 18/20
2025-05-03 13:52:19,168 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 13:53:12,244 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Validation loss improved from 0.3309 to 0.3274
2025-05-03 13:53:12,510 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 18 completed in 99.51s - Train Loss: 0.3180, Train Acc: 0.9953, Val Loss: 0.3274, Val Acc: 0.9846
2025-05-03 13:53:13,282 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 17
2025-05-03 13:53:13,282 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 19/20
2025-05-03 13:53:59,122 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 13:54:52,864 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 19 completed in 99.58s - Train Loss: 0.3188, Train Acc: 0.9942, Val Loss: 0.3297, Val Acc: 0.9837
2025-05-03 13:54:53,691 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 18
2025-05-03 13:54:53,692 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Starting epoch 20/20
2025-05-03 13:55:38,963 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 13:56:33,981 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Epoch 20 completed in 100.29s - Train Loss: 0.3186, Train Acc: 0.9944, Val Loss: 0.3299, Val Acc: 0.9828
2025-05-03 13:56:34,789 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Checkpoint saved at epoch 19
2025-05-03 13:56:34,790 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:56:46,971 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:56:46,971 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:56:46,972 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 746,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:56:46,972 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 746,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:56:46,972 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:56:46,972 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:56:47,484 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:56:47,484 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:56:47,488 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:56:47,488 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 747,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 747,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 747,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "StepLR",
    "step_size": 10,
    "gamma": 0.1
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:56:59,928 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:00,447 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:00,447 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:00,447 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:00,448 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:00,448 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:00,448 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 748,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 748,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 748,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 748,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:12,890 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:13,386 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:13,386 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:13,386 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:13,386 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:13,388 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:13,388 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:13,388 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:13,388 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 749,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 749,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 749,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 749,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 749,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:25,859 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:26,360 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:26,360 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:26,360 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:26,360 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:26,360 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:26,362 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:26,362 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:26,362 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:26,362 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:26,362 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 750,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 750,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 750,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 750,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 750,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 750,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "ReduceLROnPlateau",
    "patience": 5,
    "factor": 0.5
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:38,703 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:39,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:39,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:39,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:39,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:39,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:39,216 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:39,217 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:39,217 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:39,217 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:39,217 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:39,217 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:39,217 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,649 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 751,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:51,650 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,161 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:57:52,162 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,983 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 752,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:04,984 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,486 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:05,487 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 753,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingLR",
    "T_max": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:18,682 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,295 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:19,297 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,836 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 754,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "CrossEntropy"
  }
}
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:31,838 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,324 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:32,326 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 755,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "FocalLoss",
    "alpha": 0.25,
    "gamma": 2.0
  }
}
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:44,888 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,371 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:45,372 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Initialized training manager for model_ConvNeXt_opt_AdamW_lr_0.0001
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Config: {
  "id": 756,
  "model_name": "ConvNeXt",
  "optimizer": "AdamW",
  "learning_rate": 0.0001,
  "scheduler": {
    "name": "CosineAnnealingWarmRestarts",
    "T_0": 10
  },
  "loss_fn": {
    "name": "LabelSmoothing",
    "smoothing": 0.1
  }
}
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:57,766 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Loading checkpoint from model_results_v2/model_ConvNeXt_opt_AdamW_lr_0.0001/checkpoint.pt
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,255 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Resuming from epoch 20, best validation accuracy: 0.9854
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
2025-05-03 13:58:58,256 - training.model_ConvNeXt_opt_AdamW_lr_0.0001 - INFO - Training completed after 2006.10 seconds
